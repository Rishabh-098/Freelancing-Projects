<div align="center">
  <h1>Hi there! ğŸ‘‹ I'm Rishabh Sengar</h1>
  <p>Welcome to my GitHub repository! Here's a glimpse of my skills and expertise:</p>
  <div style="padding: 20px; background-color: #f0f0f0; border-radius: 10px; box-shadow: 0px 0px 10px 0px rgba(0,0,0,0.2);">
    <img src="https://img.shields.io/badge/Python-Expert-3776AB?logo=python&logoColor=white" alt="Python Expert" style="margin: 5px; padding: 10px; border-radius: 5px; background-color: #3776AB;">
    <img src="https://img.shields.io/badge/Web%20Scraping-Pro-FF6F61?logo=webcomponents.org&logoColor=white" alt="Web Scraping Pro" style="margin: 5px; padding: 10px; border-radius: 5px; background-color: #FF6F61;">
    <img src="https://img.shields.io/badge/API%20Integration-Pro-1ABC9C?logo=internet-explorer&logoColor=white" alt="API Integration Pro" style="margin: 5px; padding: 10px; border-radius: 5px; background-color: #1ABC9C;">
    <img src="https://img.shields.io/badge/SQL%20Master-4682B4?logo=sql&logoColor=white" alt="SQL Master" style="margin: 5px; padding: 10px; border-radius: 5px; background-color: #4682B4;">
    <img src="https://img.shields.io/badge/Data%20Analysis-Pro-F15B2A?logo=anaconda&logoColor=white" alt="Data Analysis Pro" style="margin: 5px; padding: 10px; border-radius: 5px; background-color: #F15B2A;">
    <img src="https://img.shields.io/badge/Power%20BI-Advanced-F2C811?logo=power-bi&logoColor=white" alt="Power BI Advanced" style="margin: 5px; padding: 10px; border-radius: 5px; background-color: #F2C811;">
    <img src="https://img.shields.io/badge/MongoDB-Proficient-4EA94B?logo=mongodb&logoColor=white" alt="MongoDB Proficient" style="margin: 5px; padding: 10px; border-radius: 5px; background-color: #4EA94B;">
    <img src="https://img.shields.io/badge/AWS-Expert-232F3E?logo=amazon-aws&logoColor=white" alt="AWS Expert" style="margin: 5px; padding: 10px; border-radius: 5px; background-color: #232F3E;">
    <img src="https://img.shields.io/badge/SAS-Advanced-1F76B4?logo=sas&logoColor=white" alt="SAS Advanced" style="margin: 5px; padding: 10px; border-radius: 5px; background-color: #1F76B4;">
    <img src="https://img.shields.io/badge/Excel%20Wizard-1F4068?logo=microsoft-excel&logoColor=white" alt="Excel Wizard" style="margin: 5px; padding: 10px; border-radius: 5px; background-color: #1F4068;">
  </div>
</div>




# ğŸ¢ RERA Website Scraping Project ğŸ•µï¸â€â™‚ï¸

This project aims to scrape data from the Real Estate Regulatory Authority (RERA) website, extracting project details using certificate numbers. The scraped data includes various project-related information such as project name, promoter details, project type, and more.

## Privacy Notice

- **Input Data**: The input for this project is a CSV file containing certificate numbers. Please note that certificate numbers are sensitive data and are not publicly shareable.
- **Output Data**: The output of this project is CSV files containing scraped project details. Due to privacy concerns, these files will not be shared in this repository.

## ğŸ› ï¸ Project Details

- **Programming Language**: Python ğŸ
- **Libraries Used**: Selenium, BeautifulSoup, pandas
- **Web Driver**: Microsoft Edge Chromium

## ğŸ”„ Code Workflow

1. **Read Input**: Read certificate numbers from a CSV file.
2. **Scrape Data**: Use Selenium to automate web scraping on the RERA website.
3. **Process Data**: Extract relevant project details using BeautifulSoup.
4. **Save Data**: Save scraped project details into CSV files.

## âš™ï¸ Usage

1. Clone the repository to your local machine.
2. Ensure you have Python and required libraries installed.
3. Prepare a CSV file with certificate numbers.
4. Run the Python script `rera_website_scraper.ipynb`.
5. The script will scrape project details from the RERA website using the provided certificate numbers.
6. Scrape data will be saved into CSV files named `Rera_website_scraping_data_output.csv`.

## ğŸ“ Disclaimer

This project is for educational and research purposes only. It is not intended for commercial use. The developers of this project are not responsible for any misuse of the scraped data.

ğŸ” Happy Scraping!
